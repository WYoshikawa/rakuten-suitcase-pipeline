#!/usr/bin/env python3
"""
ğŸ¦ RASCAL 3.0 Image Analysis System
æ¥½å¤©ã‚¹ãƒ¼ãƒ„ã‚±ãƒ¼ã‚¹ç”»åƒåˆ†æã‚·ã‚¹ãƒ†ãƒ  - GitHub Actionså¯¾å¿œç‰ˆ

â–¸ è‰²å½©åˆ†æï¼ˆæ”¯é…è‰²ã€å½©åº¦ã€æ˜åº¦ï¼‰
â–¸ ãƒ‡ã‚¶ã‚¤ãƒ³åˆ†é¡ï¼ˆãƒãƒ¼ãƒ‰/ã‚½ãƒ•ãƒˆã€ãƒ–ãƒ©ãƒ³ãƒ‰æ¨å®šï¼‰
â–¸ é«˜ç´šæ„Ÿè©•ä¾¡ï¼ˆè³ªæ„Ÿã€ä»•ä¸Šã’å“è³ªï¼‰
â–¸ æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ï¼ˆå•†å“åã¨ç”»åƒã®ä¸€è‡´åº¦ï¼‰
â–¸ è»½é‡ãƒ»é«˜é€ŸåŒ–ã«ã‚ˆã‚‹CI/CDå¯¾å¿œ
"""

import os
import json
import glob
import pandas as pd
import numpy as np
import requests
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
import warnings
warnings.filterwarnings('ignore')

try:
    from PIL import Image, ImageStat
    import cv2
    from sklearn.cluster import KMeans
    from colorthief import ColorThief
    import webcolors
    from io import BytesIO
    import matplotlib.pyplot as plt
    import seaborn as sns
    from concurrent.futures import ThreadPoolExecutor, as_completed
    import time
    
    DEPENDENCIES_OK = True
except ImportError as e:
    print(f"âŒ ç”»åƒåˆ†æãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒä¸è¶³: {e}")
    print("pip install pillow opencv-python scikit-learn colorthief webcolors matplotlib seaborn")
    DEPENDENCIES_OK = False

class RASCALImageAnalyzer:
    """ğŸ¦ RASCAL 3.0 ç”»åƒåˆ†æã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, max_workers=4, timeout=10):
        if not DEPENDENCIES_OK:
            raise ImportError("å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        self.max_workers = max_workers
        self.timeout = timeout
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # è‰²åãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰
        self.color_names = {
            'black': 'é»’', 'white': 'ç™½', 'gray': 'ã‚°ãƒ¬ãƒ¼', 'grey': 'ã‚°ãƒ¬ãƒ¼',
            'red': 'èµ¤', 'blue': 'é’', 'green': 'ç·‘', 'yellow': 'é»„',
            'orange': 'ã‚ªãƒ¬ãƒ³ã‚¸', 'purple': 'ç´«', 'pink': 'ãƒ”ãƒ³ã‚¯',
            'brown': 'èŒ¶', 'silver': 'ã‚·ãƒ«ãƒãƒ¼', 'gold': 'ã‚´ãƒ¼ãƒ«ãƒ‰',
            'navy': 'ãƒã‚¤ãƒ“ãƒ¼', 'beige': 'ãƒ™ãƒ¼ã‚¸ãƒ¥'
        }
    
    def download_image(self, url: str, max_size=(400, 400)) -> Optional[Image.Image]:
        """ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚µã‚¤ã‚ºåˆ¶é™ãƒ»é«˜é€ŸåŒ–ï¼‰"""
        try:
            response = self.session.get(url, timeout=self.timeout, stream=True)
            response.raise_for_status()
            
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆ5MBåˆ¶é™ï¼‰
            content_length = response.headers.get('content-length')
            if content_length and int(content_length) > 5 * 1024 * 1024:
                return None
            
            # ç”»åƒèª­ã¿è¾¼ã¿
            image = Image.open(BytesIO(response.content))
            
            # ã‚µã‚¤ã‚ºèª¿æ•´ï¼ˆé«˜é€ŸåŒ–ï¼‰
            if image.size[0] > max_size[0] or image.size[1] > max_size[1]:
                image.thumbnail(max_size, Image.Resampling.LANCZOS)
            
            # RGBå¤‰æ›
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            return image
            
        except Exception as e:
            print(f"ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ {url}: {e}")
            return None
    
    def analyze_dominant_colors(self, image: Image.Image, num_colors=5) -> List[Dict]:
        """æ”¯é…è‰²åˆ†æï¼ˆé«˜é€ŸåŒ–ç‰ˆï¼‰"""
        try:
            # ç”»åƒã‚’ã•ã‚‰ã«ç¸®å°ï¼ˆé«˜é€ŸåŒ–ï¼‰
            temp_image = image.copy()
            temp_image.thumbnail((150, 150), Image.Resampling.LANCZOS)
            
            # numpyé…åˆ—ã«å¤‰æ›
            img_array = np.array(temp_image)
            pixels = img_array.reshape(-1, 3)
            
            # K-means ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
            kmeans = KMeans(n_clusters=min(num_colors, len(np.unique(pixels, axis=0))), 
                          random_state=42, n_init=10)
            kmeans.fit(pixels)
            
            colors = []
            total_pixels = len(pixels)
            
            for i, color in enumerate(kmeans.cluster_centers_):
                color_rgb = tuple(map(int, color))
                percentage = np.sum(kmeans.labels_ == i) / total_pixels * 100
                
                # è‰²åæ¨å®š
                color_name = self.get_color_name(color_rgb)
                
                colors.append({
                    'rgb': color_rgb,
                    'hex': '#{:02x}{:02x}{:02x}'.format(*color_rgb),
                    'percentage': round(percentage, 1),
                    'name': color_name
                })
            
            # å‰²åˆé †ã«ã‚½ãƒ¼ãƒˆ
            colors.sort(key=lambda x: x['percentage'], reverse=True)
            return colors
            
        except Exception as e:
            print(f"è‰²å½©åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def get_color_name(self, rgb: Tuple[int, int, int]) -> str:
        """RGBå€¤ã‹ã‚‰è‰²åã‚’æ¨å®š"""
        try:
            # webcolorsã§æœ€è¿‘ä¼¼è‰²ã‚’æ¤œç´¢
            closest_name = webcolors.rgb_to_name(rgb)
            return self.color_names.get(closest_name, closest_name)
        except ValueError:
            # æœ€è¿‘ä¼¼è‰²ã‚’æ‰‹å‹•è¨ˆç®—
            min_distance = float('inf')
            closest_name = 'ä¸æ˜'
            
            for hex_color, name in webcolors.CSS3_HEX_TO_NAMES.items():
                hex_rgb = webcolors.hex_to_rgb(hex_color)
                distance = sum((c1 - c2) ** 2 for c1, c2 in zip(rgb, hex_rgb))
                if distance < min_distance:
                    min_distance = distance
                    closest_name = self.color_names.get(name, name)
            
            return closest_name
    
    def analyze_image_quality(self, image: Image.Image) -> Dict[str, float]:
        """ç”»åƒå“è³ªãƒ»é«˜ç´šæ„Ÿåˆ†æ"""
        try:
            # åŸºæœ¬çµ±è¨ˆ
            stat = ImageStat.Stat(image)
            
            # å½©åº¦è¨ˆç®—
            hsv_image = image.convert('HSV')
            hsv_stat = ImageStat.Stat(hsv_image)
            saturation = hsv_stat.mean[1] / 255.0
            
            # æ˜åº¦
            brightness = sum(stat.mean) / (255.0 * 3)
            
            # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆï¼ˆæ¨™æº–åå·®ãƒ™ãƒ¼ã‚¹ï¼‰
            contrast = sum(stat.stddev) / (255.0 * 3)
            
            # é®®æ˜åº¦ï¼ˆã‚¨ãƒƒã‚¸æ¤œå‡ºãƒ™ãƒ¼ã‚¹ï¼‰
            gray = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)
            laplacian = cv2.Laplacian(gray, cv2.CV_64F)
            sharpness = laplacian.var() / 10000.0  # æ­£è¦åŒ–
            
            # é«˜ç´šæ„Ÿã‚¹ã‚³ã‚¢ï¼ˆè¤‡åˆæŒ‡æ¨™ï¼‰
            luxury_score = (
                saturation * 0.3 +           # é©åº¦ãªå½©åº¦
                contrast * 0.4 +             # é«˜ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ  
                min(sharpness, 1.0) * 0.3    # é®®æ˜åº¦ï¼ˆä¸Šé™1.0ï¼‰
            ) * 100
            
            return {
                'brightness': round(brightness, 3),
                'saturation': round(saturation, 3),
                'contrast': round(contrast, 3),
                'sharpness': round(min(sharpness, 1.0), 3),
                'luxury_score': round(min(luxury_score, 100), 1)
            }
            
        except Exception as e:
            print(f"å“è³ªåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'brightness': 0.5, 'saturation': 0.5, 'contrast': 0.5,
                'sharpness': 0.5, 'luxury_score': 50.0
            }
    
    def classify_suitcase_type(self, image: Image.Image, item_name: str) -> Dict[str, Any]:
        """ã‚¹ãƒ¼ãƒ„ã‚±ãƒ¼ã‚¹åˆ†é¡ï¼ˆãƒãƒ¼ãƒ‰/ã‚½ãƒ•ãƒˆã€ãƒ–ãƒ©ãƒ³ãƒ‰æ¨å®šï¼‰"""
        try:
            # è‰²å½©ã«ã‚ˆã‚‹åˆ†é¡
            colors = self.analyze_dominant_colors(image, 3)
            dominant_color = colors[0] if colors else {'name': 'ä¸æ˜', 'percentage': 0}
            
            # æè³ªæ¨å®šï¼ˆè‰²ãƒ»è³ªæ„Ÿãƒ™ãƒ¼ã‚¹ï¼‰
            material_hints = []
            if any(color['name'] in ['é»’', 'ã‚°ãƒ¬ãƒ¼', 'ã‚·ãƒ«ãƒãƒ¼'] for color in colors):
                material_hints.append('ãƒãƒ¼ãƒ‰ã‚±ãƒ¼ã‚¹')
            if any(color['name'] in ['èŒ¶', 'ãƒ™ãƒ¼ã‚¸ãƒ¥', 'é»’'] for color in colors):
                material_hints.append('ãƒ¬ã‚¶ãƒ¼èª¿')
            
            # å•†å“åã¨ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            name_lower = item_name.lower()
            consistency_score = 0
            
            # ãƒãƒ¼ãƒ‰/ã‚½ãƒ•ãƒˆåˆ¤å®š
            if 'ãƒãƒ¼ãƒ‰' in item_name and dominant_color['name'] in ['é»’', 'ã‚°ãƒ¬ãƒ¼', 'ã‚·ãƒ«ãƒãƒ¼']:
                consistency_score += 30
            elif 'ã‚½ãƒ•ãƒˆ' in item_name and dominant_color['name'] in ['é»’', 'èŒ¶', 'ãƒã‚¤ãƒ“ãƒ¼']:
                consistency_score += 30
            
            # è‰²åæ•´åˆæ€§
            if dominant_color['name'] in item_name:
                consistency_score += 20
            
            # ã‚µã‚¤ã‚ºæ¨å®šï¼ˆã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ãƒ™ãƒ¼ã‚¹ï¼‰
            width, height = image.size
            aspect_ratio = width / height
            size_estimate = 'ä¸­å‹' if 0.7 <= aspect_ratio <= 1.3 else ('æ¨ªé•·' if aspect_ratio > 1.3 else 'ç¸¦é•·')
            
            return {
                'dominant_color': dominant_color['name'],
                'material_hints': material_hints,
                'size_estimate': size_estimate,
                'consistency_score': min(consistency_score, 100),
                'aspect_ratio': round(aspect_ratio, 2)
            }
            
        except Exception as e:
            print(f"åˆ†é¡ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'dominant_color': 'ä¸æ˜', 'material_hints': [], 'size_estimate': 'ä¸æ˜',
                'consistency_score': 0, 'aspect_ratio': 1.0
            }
    
    def analyze_single_image(self, row: pd.Series) -> Dict[str, Any]:
        """å˜ä¸€å•†å“ã®ç”»åƒåˆ†æ"""
        try:
            image_url = row.get('imageUrl', '')
            if not image_url:
                return self.create_empty_result(row, "ç”»åƒURLãªã—")
            
            # ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            image = self.download_image(image_url)
            if image is None:
                return self.create_empty_result(row, "ç”»åƒå–å¾—å¤±æ•—")
            
            # å„ç¨®åˆ†æå®Ÿè¡Œ
            colors = self.analyze_dominant_colors(image)
            quality = self.analyze_image_quality(image)
            classification = self.classify_suitcase_type(image, row.get('itemName', ''))
            
            return {
                'rank': int(row.get('rank', 0)),
                'itemCode': str(row.get('itemCode', '')),
                'itemName': str(row.get('itemName', ''))[:100],  # é•·ã™ãã‚‹åå‰ã¯åˆ‡ã‚Šæ¨ã¦
                'price': int(row.get('itemPrice', 0)),
                'imageUrl': image_url,
                'analysis_status': 'success',
                'colors': colors[:3],  # ä¸Šä½3è‰²ã®ã¿
                'quality': quality,
                'classification': classification,
                'analyzed_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            return self.create_empty_result(row, f"åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def create_empty_result(self, row: pd.Series, reason: str) -> Dict[str, Any]:
        """ç©ºã®åˆ†æçµæœã‚’ç”Ÿæˆ"""
        return {
            'rank': int(row.get('rank', 0)),
            'itemCode': str(row.get('itemCode', '')),
            'itemName': str(row.get('itemName', ''))[:100],
            'price': int(row.get('itemPrice', 0)),
            'imageUrl': row.get('imageUrl', ''),
            'analysis_status': 'failed',
            'error_reason': reason,
            'colors': [],
            'quality': {'brightness': 0, 'saturation': 0, 'contrast': 0, 'sharpness': 0, 'luxury_score': 0},
            'classification': {'dominant_color': 'ä¸æ˜', 'material_hints': [], 'size_estimate': 'ä¸æ˜', 'consistency_score': 0},
            'analyzed_at': datetime.now().isoformat()
        }
    
    def run_batch_analysis(self, csv_file: str, max_items: int = 100) -> str:
        """ğŸ¦ ãƒãƒƒãƒç”»åƒåˆ†æï¼ˆGitHub Actionsæœ€é©åŒ–ï¼‰"""
        print(f"ğŸ¨ RASCAL 3.0 ç”»åƒåˆ†æé–‹å§‹: {csv_file}")
        
        # CSVèª­ã¿è¾¼ã¿
        try:
            df = pd.read_csv(csv_file)
            print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(df)}ä»¶")
        except Exception as e:
            print(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return ""
        
        # ç”»åƒURLãŒã‚ã‚‹è¡Œã®ã¿æŠ½å‡º
        df_with_images = df[df['imageUrl'].notna() & (df['imageUrl'] != '')].copy()
        total_images = len(df_with_images)
        
        if total_images == 0:
            print("âŒ åˆ†æå¯èƒ½ãªç”»åƒURLãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return ""
        
        # GitHub Actionsç’°å¢ƒã§ã¯å‡¦ç†æ•°ã‚’åˆ¶é™
        if total_images > max_items:
            print(f"âš¡ å‡¦ç†æ•°ã‚’{max_items}ä»¶ã«åˆ¶é™ï¼ˆGitHub Actionsæœ€é©åŒ–ï¼‰")
            df_with_images = df_with_images.head(max_items)
        
        print(f"ğŸ¨ ç”»åƒåˆ†æå¯¾è±¡: {len(df_with_images)}ä»¶")
        
        # ä¸¦åˆ—åˆ†æå®Ÿè¡Œ
        results = []
        successful_analyses = 0
        
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # åˆ†æã‚¿ã‚¹ã‚¯æŠ•å…¥
            future_to_row = {
                executor.submit(self.analyze_single_image, row): idx 
                for idx, row in df_with_images.iterrows()
            }
            
            # çµæœå›å
            for future in as_completed(future_to_row):
                result = future.result()
                results.append(result)
                
                if result['analysis_status'] == 'success':
                    successful_analyses += 1
                
                # é€²æ—è¡¨ç¤º
                if len(results) % 10 == 0:
                    print(f"ğŸ”„ åˆ†æé€²æ—: {len(results)}/{len(df_with_images)}ä»¶")
        
        analysis_time = time.time() - start_time
        
        # çµ±è¨ˆè¨ˆç®—
        stats = self.calculate_analysis_statistics(results)
        
        # çµæœæ§‹ç¯‰
        final_result = {
            'metadata': {
                'analyzed_at': datetime.now().isoformat(),
                'source_file': os.path.basename(csv_file),
                'total_items': len(df),
                'analyzed_items': len(results),
                'successful_analyses': successful_analyses,
                'success_rate': round((successful_analyses / len(results)) * 100, 1),
                'analysis_time_seconds': round(analysis_time, 1),
                'items_per_second': round(len(results) / analysis_time, 2)
            },
            'statistics': stats,
            'detailed_results': results
        }
        
        # çµæœä¿å­˜
        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        output_file = f"image_analysis_{timestamp}.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(final_result, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ç”»åƒåˆ†æå®Œäº†: {output_file}")
        print(f"ğŸ“Š æˆåŠŸç‡: {final_result['metadata']['success_rate']}%")
        print(f"âš¡ å‡¦ç†é€Ÿåº¦: {final_result['metadata']['items_per_second']}ä»¶/ç§’")
        
        return output_file
    
    def calculate_analysis_statistics(self, results: List[Dict]) -> Dict[str, Any]:
        """åˆ†æçµ±è¨ˆè¨ˆç®—"""
        successful_results = [r for r in results if r['analysis_status'] == 'success']
        
        if not successful_results:
            return {'error': 'åˆ†ææˆåŠŸãƒ‡ãƒ¼ã‚¿ãªã—'}
        
        # è‰²å½©çµ±è¨ˆ
        all_colors = []
        for result in successful_results:
            for color in result['colors']:
                all_colors.append(color['name'])
        
        color_counts = {}
        for color in all_colors:
            color_counts[color] = color_counts.get(color, 0) + 1
        
        top_colors = sorted(color_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        
        # å“è³ªçµ±è¨ˆ
        luxury_scores = [r['quality']['luxury_score'] for r in successful_results]
        avg_luxury_score = sum(luxury_scores) / len(luxury_scores) if luxury_scores else 0
        
        # ä¾¡æ ¼å¸¯åˆ¥åˆ†æ
        price_ranges = {'~20000': 0, '20000-40000': 0, '40000-60000': 0, '60000+': 0}
        for result in successful_results:
            price = result['price']
            if price < 20000:
                price_ranges['~20000'] += 1
            elif price < 40000:
                price_ranges['20000-40000'] += 1
            elif price < 60000:
                price_ranges['40000-60000'] += 1
            else:
                price_ranges['60000+'] += 1
        
        return {
            'color_analysis': {
                'top_colors': [{'color': color, 'count': count} for color, count in top_colors],
                'unique_colors': len(color_counts)
            },
            'quality_analysis': {
                'average_luxury_score': round(avg_luxury_score, 1),
                'high_quality_items': len([s for s in luxury_scores if s >= 70]),
                'luxury_score_distribution': {
                    'high': len([s for s in luxury_scores if s >= 70]),
                    'medium': len([s for s in luxury_scores if 40 <= s < 70]),
                    'low': len([s for s in luxury_scores if s < 40])
                }
            },
            'price_range_analysis': price_ranges
        }

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    if not DEPENDENCIES_OK:
        print("âŒ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    # ç”»åƒä»˜ãCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    image_csv_files = glob.glob("rank_base_*_with_images.csv")
    
    if not image_csv_files:
        print("âŒ ç”»åƒä»˜ãCSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("ğŸ’¡ python rakuten_rank_step1.py --with-images ã§ç”»åƒä»˜ããƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ãã ã•ã„")
        return
    
    # æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
    latest_file = max(image_csv_files, key=os.path.getctime)
    print(f"ğŸ¯ åˆ†æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {latest_file}")
    
    # åˆ†æå®Ÿè¡Œ
    analyzer = RASCALImageAnalyzer(max_workers=3, timeout=8)  # GitHub Actionsç”¨ã«è»½é‡åŒ–
    result_file = analyzer.run_batch_analysis(latest_file, max_items=50)  # 50ä»¶åˆ¶é™
    
    if result_file:
        print(f"ğŸ¦ RASCAL 3.0 ç”»åƒåˆ†æå®Œäº†ï¼")
        print(f"ğŸ“ çµæœãƒ•ã‚¡ã‚¤ãƒ«: {result_file}")
        print(f"ğŸ¨ ã‚¹ãƒ¼ãƒ„ã‚±ãƒ¼ã‚¹å¸‚å ´ã®è¦–è¦šçš„æ´å¯Ÿã‚’ç²å¾—ã—ã¾ã—ãŸï¼")

if __name__ == "__main__":
    main()
