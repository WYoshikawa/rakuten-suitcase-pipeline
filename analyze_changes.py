#!/usr/bin/env python3
"""
ğŸ¨ RASCAL 3.0 Enhanced Changes Analyzer with Image Analysis
ç”»åƒåˆ†æãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€æ¥½å¤©ã‚¹ãƒ¼ãƒ„ã‚±ãƒ¼ã‚¹ãƒ©ãƒ³ã‚­ãƒ³ã‚°å¤‰åŒ–åˆ†æ

ç”»åƒåˆ†æçµæœã‚’æ´»ç”¨ã—ãŸæ–°ã—ã„æ´å¯Ÿ:
- è‰²å½©ãƒˆãƒ¬ãƒ³ãƒ‰ã®å¤‰åŒ–
- é«˜ç´šæ„Ÿã‚¹ã‚³ã‚¢ã®æ¨ç§»  
- ãƒ‡ã‚¶ã‚¤ãƒ³å‚¾å‘ã®åˆ†æ
- ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«æˆ¦ç•¥ã®åŠ¹æœæ¸¬å®š
"""

import pandas as pd
import json
import glob
import os
from datetime import datetime
from typing import Dict, List, Any, Optional

class RASCALImageChangesAnalyzer:
    """ğŸ¨ RASCAL 3.0 ç”»åƒåˆ†æå¯¾å¿œå¤‰åŒ–åˆ†æå™¨"""
    
    def __init__(self):
        self.data_dir = "data"
        self.changes_dir = os.path.join(self.data_dir, "changes")
        self.images_dir = os.path.join(self.data_dir, "images")
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(self.changes_dir, exist_ok=True)
        os.makedirs(self.images_dir, exist_ok=True)
    
    def find_latest_files(self) -> tuple[str, str]:
        """æœ€æ–°ã¨å‰æ—¥ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ï¼ˆç”»åƒå¯¾å¿œï¼‰"""
        # ç”»åƒä»˜ããƒ•ã‚¡ã‚¤ãƒ«ã‚’å„ªå…ˆ
        image_csv_files = glob.glob(os.path.join(self.data_dir, "rank_base_*_with_images.csv"))
        regular_csv_files = glob.glob(os.path.join(self.data_dir, "rank_base_*.csv"))
        
        all_csv_files = image_csv_files + [f for f in regular_csv_files if "_with_images" not in f]
        
        if len(all_csv_files) < 2:
            raise FileNotFoundError("æ¯”è¼ƒã«å¿…è¦ãª2ã¤ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        all_csv_files.sort()
        return all_csv_files[-1], all_csv_files[-2]  # æœ€æ–°, å‰æ—¥
    
    def find_latest_image_analysis(self) -> Optional[str]:
        """æœ€æ–°ã®ç”»åƒåˆ†æçµæœã‚’å–å¾—"""
        json_files = glob.glob(os.path.join(self.images_dir, "image_analysis_*.json"))
        if not json_files:
            json_files = glob.glob("image_analysis_*.json")
        
        if json_files:
            return max(json_files, key=os.path.getctime)
        return None
    
    def load_image_analysis_data(self) -> Optional[Dict]:
        """ç”»åƒåˆ†æãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        image_analysis_file = self.find_latest_image_analysis()
        if not image_analysis_file:
            return None
        
        try:
            with open(image_analysis_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"ç”»åƒåˆ†æãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def analyze_color_trends(self, today_df: pd.DataFrame, image_data: Dict) -> Dict[str, Any]:
        """è‰²å½©ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        if not image_data or 'detailed_results' not in image_data:
            return {'error': 'ç”»åƒåˆ†æãƒ‡ãƒ¼ã‚¿ãªã—'}
        
        try:
            # ä»Šæ—¥ã®è‰²å½©ãƒ‡ãƒ¼ã‚¿åé›†
            color_distribution = {}
            luxury_by_color = {}
            price_by_color = {}
            
            for result in image_data['detailed_results']:
                if result['analysis_status'] != 'success':
                    continue
                
                for color_info in result['colors']:
                    color_name = color_info['name']
                    percentage = color_info['percentage']
                    
                    if color_name not in color_distribution:
                        color_distribution[color_name] = {'count': 0, 'total_percentage': 0, 'items': []}
                    
                    color_distribution[color_name]['count'] += 1
                    color_distribution[color_name]['total_percentage'] += percentage
                    color_distribution[color_name]['items'].append({
                        'rank': result['rank'],
                        'price': result['price'],
                        'luxury_score': result['quality']['luxury_score']
                    })
            
            # è‰²åˆ¥çµ±è¨ˆè¨ˆç®—
            color_stats = []
            for color, data in color_distribution.items():
                if data['count'] >= 2:  # 2ä»¶ä»¥ä¸Šã®è‰²ã®ã¿
                    avg_price = sum(item['price'] for item in data['items']) / len(data['items'])
                    avg_luxury = sum(item['luxury_score'] for item in data['items']) / len(data['items'])
                    avg_rank = sum(item['rank'] for item in data['items']) / len(data['items'])
                    
                    color_stats.append({
                        'color': color,
                        'count': data['count'],
                        'market_share': round((data['count'] / len(image_data['detailed_results'])) * 100, 1),
                        'avg_price': round(avg_price, 0),
                        'avg_luxury_score': round(avg_luxury, 1),
                        'avg_rank': round(avg_rank, 1)
                    })
            
            # äººæ°—è‰²é †ã«ã‚½ãƒ¼ãƒˆ
            color_stats.sort(key=lambda x: x['count'], reverse=True)
            
            return {
                'top_colors': color_stats[:5],
                'total_colors_analyzed': len(color_distribution),
                'high_luxury_colors': [c for c in color_stats if c['avg_luxury_score'] >= 70],
                'premium_price_colors': [c for c in color_stats if c['avg_price'] >= 40000]
            }
            
        except Exception as e:
            return {'error': f'è‰²å½©ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚¨ãƒ©ãƒ¼: {e}'}
    
    def analyze_visual_quality_trends(self, image_data: Dict) -> Dict[str, Any]:
        """ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        if not image_data or 'detailed_results' not in image_data:
            return {'error': 'ç”»åƒåˆ†æãƒ‡ãƒ¼ã‚¿ãªã—'}
        
        try:
            successful_results = [r for r in image_data['detailed_results'] if r['analysis_status'] == 'success']
            
            if not successful_results:
                return {'error': 'åˆ†ææˆåŠŸãƒ‡ãƒ¼ã‚¿ãªã—'}
            
            # å“è³ªæŒ‡æ¨™é›†è¨ˆ
            quality_metrics = {
                'luxury_scores': [r['quality']['luxury_score'] for r in successful_results],
                'brightness': [r['quality']['brightness'] for r in successful_results],
                'saturation': [r['quality']['saturation'] for r in successful_results],
                'contrast': [r['quality']['contrast'] for r in successful_results]
            }
            
            # çµ±è¨ˆè¨ˆç®—
            stats = {}
            for metric, values in quality_metrics.items():
                stats[metric] = {
                    'average': round(sum(values) / len(values), 2),
                    'max': round(max(values), 2),
                    'min': round(min(values), 2)
                }
            
            # ãƒ©ãƒ³ã‚¯åˆ¥å“è³ªåˆ†æ
            rank_quality = {'top30': [], 'middle': [], 'lower': []}
            for result in successful_results:
                rank = result['rank']
                luxury_score = result['quality']['luxury_score']
                
                if rank <= 30:
                    rank_quality['top30'].append(luxury_score)
                elif rank <= 70:
                    rank_quality['middle'].append(luxury_score)
                else:
                    rank_quality['lower'].append(luxury_score)
            
            rank_quality_stats = {}
            for category, scores in rank_quality.items():
                if scores:
                    rank_quality_stats[category] = {
                        'average_luxury': round(sum(scores) / len(scores), 1),
                        'count': len(scores)
                    }
            
            return {
                'overall_quality': stats,
                'rank_quality_correlation': rank_quality_stats,
                'high_quality_count': len([s for s in quality_metrics['luxury_scores'] if s >= 70]),
                'quality_distribution': {
                    'excellent': len([s for s in quality_metrics['luxury_scores'] if s >= 80]),
                    'good': len([s for s in quality_metrics['luxury_scores'] if 60 <= s < 80]),
                    'average': len([s for s in quality_metrics['luxury_scores'] if 40 <= s < 60]),
                    'poor': len([s for s in quality_metrics['luxury_scores'] if s < 40])
                }
            }
            
        except Exception as e:
            return {'error': f'å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚¨ãƒ©ãƒ¼: {e}'}
    
    def analyze_design_consistency(self, image_data: Dict) -> Dict[str, Any]:
        """ãƒ‡ã‚¶ã‚¤ãƒ³æ•´åˆæ€§åˆ†æ"""
        if not image_data or 'detailed_results' not in image_data:
            return {'error': 'ç”»åƒåˆ†æãƒ‡ãƒ¼ã‚¿ãªã—'}
        
        try:
            successful_results = [r for r in image_data['detailed_results'] if r['analysis_status'] == 'success']
            
            consistency_scores = [r['classification']['consistency_score'] for r in successful_results]
            
            if not consistency_scores:
                return {'error': 'æ•´åˆæ€§ãƒ‡ãƒ¼ã‚¿ãªã—'}
            
            avg_consistency = sum(consistency_scores) / len(consistency_scores)
            
            # æ•´åˆæ€§ãƒ¬ãƒ™ãƒ«åˆ¥åˆ†é¡
            consistency_levels = {
                'excellent': len([s for s in consistency_scores if s >= 80]),
                'good': len([s for s in consistency_scores if 60 <= s < 80]),
                'fair': len([s for s in consistency_scores if 40 <= s < 60]),
                'poor': len([s for s in consistency_scores if s < 40])
            }
            
            # ä½æ•´åˆæ€§å•†å“ã®ç‰¹å®š
            low_consistency_items = []
            for result in successful_results:
                if result['classification']['consistency_score'] < 50:
                    low_consistency_items.append({
                        'rank': result['rank'],
                        'name': result['itemName'][:50],
                        'consistency_score': result['classification']['consistency_score'],
                        'dominant_color': result['classification']['dominant_color']
                    })
            
            return {
                'average_consistency': round(avg_consistency, 1),
                'consistency_distribution': consistency_levels,
                'low_consistency_items': low_consistency_items[:5],  # ä¸Šä½5ä»¶
                'total_analyzed': len(consistency_scores)
            }
            
        except Exception as e:
            return {'error': f'æ•´åˆæ€§åˆ†æã‚¨ãƒ©ãƒ¼: {e}'}
    
    def run_enhanced_analysis(self) -> str:
        """ğŸ¨ RASCAL 3.0 æ‹¡å¼µåˆ†æå®Ÿè¡Œ"""
        print("ğŸ¨ RASCAL 3.0 Enhanced Changes Analyzer é–‹å§‹...")
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
            today_file, yesterday_file = self.find_latest_files()
            print(f"ğŸ“Š æ¯”è¼ƒå¯¾è±¡: {os.path.basename(yesterday_file)} â†’ {os.path.basename(today_file)}")
            
            # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            today_df = pd.read_csv(today_file)
            yesterday_df = pd.read_csv(yesterday_file)
            
            # ç”»åƒåˆ†æãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            image_data = self.load_image_analysis_data()
            has_image_analysis = image_data is not None
            
            print(f"ğŸ¨ ç”»åƒåˆ†æãƒ‡ãƒ¼ã‚¿: {'æœ‰åŠ¹' if has_image_analysis else 'ç„¡åŠ¹'}")
            
            # åŸºæœ¬å¤‰åŒ–åˆ†æï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
            basic_analysis = self.run_basic_analysis(today_df, yesterday_df)
            
            # æ‹¡å¼µåˆ†æï¼ˆç”»åƒãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆï¼‰
            enhanced_analysis = {}
            if has_image_analysis:
                print("ğŸ¨ è‰²å½©ãƒ»å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æä¸­...")
                enhanced_analysis = {
                    'color_trends': self.analyze_color_trends(today_df, image_data),
                    'visual_quality': self.analyze_visual_quality_trends(image_data),
                    'design_consistency': self.analyze_design_consistency(image_data),
                    'image_analysis_metadata': image_data.get('metadata', {})
                }
            
            # çµæœçµ±åˆ
            result = {
                'timestamp': datetime.now().isoformat(),
                'analysis_type': 'enhanced_with_images' if has_image_analysis else 'basic',
                'source_files': {
                    'current': os.path.basename(today_file),
                    'previous': os.path.basename(yesterday_file)
                },
                'basic_analysis': basic_analysis,
                'enhanced_analysis': enhanced_analysis if has_image_analysis else None,
                'summary': self.generate_enhanced_summary(basic_analysis, enhanced_analysis, has_image_analysis)
            }
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
            timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M")
            output_file = os.path.join(self.changes_dir, f"enhanced_changes_{timestamp}.json")
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… æ‹¡å¼µåˆ†æå®Œäº†: {output_file}")
            if has_image_analysis:
                print("ğŸ¨ ç”»åƒåˆ†æã«ã‚ˆã‚‹æ–°ã—ã„æ´å¯ŸãŒå«ã¾ã‚Œã¦ã„ã¾ã™ï¼")
            
            return output_file
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
            raise
    
    def run_basic_analysis(self, today_df: pd.DataFrame, yesterday_df: pd.DataFrame) -> Dict[str, Any]:
        """åŸºæœ¬å¤‰åŒ–åˆ†æï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰"""
        # ä¾¡æ ¼å¤‰åŒ–
        today_avg = today_df['itemPrice'].mean()
        yesterday_avg = yesterday_df['itemPrice'].mean()
        price_change = ((today_avg - yesterday_avg) / yesterday_avg) * 100
        
        # å•†å“å…¥ã‚Œæ›¿ã‚ã‚Š
        today_codes = set(today_df['itemCode'])
        yesterday_codes = set(yesterday_df['itemCode'])
        
        new_items = len(today_codes - yesterday_codes)
        dropped_items = len(yesterday_codes - today_codes)
        common_items = len(today_codes & yesterday_codes)
        
        return {
            'price_analysis': {
                'today_average': round(today_avg, 0),
                'yesterday_average': round(yesterday_avg, 0),
                'change_percent': round(price_change, 1)
            },
            'market_dynamics': {
                'new_entries': new_items,
                'dropped_items': dropped_items,
                'continuing_items': common_items,
                'turnover_rate': round((new_items + dropped_items) / len(today_df) * 100, 1)
            }
        }
    
    def generate_enhanced_summary(self, basic: Dict, enhanced: Dict, has_images: bool) -> Dict[str, str]:
        """æ‹¡å¼µã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        summary = {
            'market_trend': f"å¹³å‡ä¾¡æ ¼{basic['price_analysis']['change_percent']:+.1f}%å¤‰å‹•",
            'market_fluidity': f"å•†å“å…¥ã‚Œæ›¿ã‚ã‚Šç‡{basic['market_dynamics']['turnover_rate']:.1f}%"
        }
        
        if has_images and enhanced and 'color_trends' in enhanced:
            color_data = enhanced['color_trends']
            if 'top_colors' in color_data and color_data['top_colors']:
                top_color = color_data['top_colors'][0]['color']
                summary['visual_trend'] = f"æ”¯é…è‰²: {top_color}"
            
            if 'visual_quality' in enhanced:
                quality_data = enhanced['visual_quality']
                if 'overall_quality' in quality_data:
                    avg_luxury = quality_data['overall_quality'].get('luxury_scores', {}).get('average', 0)
                    summary['quality_trend'] = f"å¹³å‡é«˜ç´šæ„Ÿã‚¹ã‚³ã‚¢: {avg_luxury:.1f}ç‚¹"
        
        return summary

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    analyzer = RASCALImageChangesAnalyzer()
    result_file = analyzer.run_enhanced_analysis()
    
    print(f"\nğŸ¦ RASCAL 3.0 æ‹¡å¼µåˆ†æå®Œäº†ï¼")
    print(f"ğŸ“ çµæœãƒ•ã‚¡ã‚¤ãƒ«: {result_file}")
    print(f"ğŸ¨ ç”»åƒåˆ†æã«ã‚ˆã‚‹æ·±ã„å¸‚å ´æ´å¯Ÿã‚’ç²å¾—ã—ã¾ã—ãŸï¼")

if __name__ == "__main__":
    main()
