#!/usr/bin/env python3
"""
ğŸ¦ RASCAL Optimized Changes Analyzer
æ¥½å¤©ã‚¹ãƒ¼ãƒ„ã‚±ãƒ¼ã‚¹ãƒ©ãƒ³ã‚­ãƒ³ã‚°å¤‰åŒ–åˆ†æï¼ˆè»½é‡åŒ–ç‰ˆï¼‰

é‡è¦åº¦ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹åŠ¹ç‡çš„ãªå¤‰åŒ–æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ 
- ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ¶é™å¯¾å¿œ
- å“è³ªã‚’ä¿æŒã—ãŸæƒ…å ±åœ§ç¸®
- éšå±¤åŒ–ã•ã‚ŒãŸé‡è¦åº¦åˆ†é¡
"""

import pandas as pd
import json
import glob
import os
from datetime import datetime
from typing import Dict, List, Any, Optional

class RASCALChangesAnalyzer:
    """RASCALæ¨å¥¨ã®é‡è¦åº¦ãƒ™ãƒ¼ã‚¹å¤‰åŒ–åˆ†æå™¨"""
    
    def __init__(self):
        self.data_dir = "data"
        self.changes_dir = os.path.join(self.data_dir, "changes")
        
        # é‡è¦åº¦åˆ¤å®šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        self.special_keywords = [
            'TV', 'ZIP', 'ãƒ†ãƒ¬ãƒ“', 'ãƒ’ãƒ«ãƒŠãƒ³ãƒ‡ã‚¹', 'ã‚µã‚¿ãƒ—ãƒ©',
            'æ¥½å¤©1ä½', 'ãƒ©ãƒ³ã‚­ãƒ³ã‚°1ä½', '1ä½ç²å¾—',
            'RIMOWA', 'ã‚µãƒ ã‚½ãƒŠã‚¤ãƒˆ', 'ãƒ—ãƒ­ãƒ†ã‚«'
        ]
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(self.changes_dir, exist_ok=True)
    
    def find_latest_files(self) -> tuple[str, str]:
        """æœ€æ–°ã¨å‰æ—¥ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—"""
        csv_files = glob.glob(os.path.join(self.data_dir, "rank_base_*.csv"))
        
        if len(csv_files) < 2:
            raise FileNotFoundError("æ¯”è¼ƒã«å¿…è¦ãª2ã¤ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã§ã‚½ãƒ¼ãƒˆï¼ˆæ—¥ä»˜é †ï¼‰
        csv_files.sort()
        
        return csv_files[-1], csv_files[-2]  # æœ€æ–°, å‰æ—¥
    
    def load_data(self, filepath: str) -> pd.DataFrame:
        """CSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        df = pd.read_csv(filepath)
        
        # ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›
        df['rank'] = df['rank'].astype(int)
        df['itemPrice'] = df['itemPrice'].astype(int)
        df['reviewAverage'] = pd.to_numeric(df['reviewAverage'], errors='coerce').fillna(0)
        df['reviewCount'] = df['reviewCount'].astype(int)
        
        return df
    
    def calculate_importance_score(self, item: Dict[str, Any]) -> int:
        """ğŸ¯ RASCALé‡è¦åº¦ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°"""
        score = 0
        
        # é †ä½ã«ã‚ˆã‚‹é‡è¦åº¦
        rank = item.get('rank', 999)
        if rank <= 30:
            score += 3
        elif rank <= 100:
            score += 2
        elif rank <= 200:
            score += 1
        
        # å¤‰å‹•å¹…ã«ã‚ˆã‚‹é‡è¦åº¦
        rank_change = abs(item.get('rank_change', 0))
        if rank_change >= 50:
            score += 3
        elif rank_change >= 20:
            score += 2
        elif rank_change >= 10:
            score += 1
        
        # ä¾¡æ ¼ã«ã‚ˆã‚‹é‡è¦åº¦
        price = item.get('price', 0)
        if price >= 50000:
            score += 3
        elif price >= 30000:
            score += 2
        elif price >= 15000:
            score += 1
        
        # ä¾¡æ ¼å¤‰å‹•ã«ã‚ˆã‚‹é‡è¦åº¦
        price_change = abs(item.get('price_change_percent', 0))
        if price_change >= 20:
            score += 3
        elif price_change >= 10:
            score += 2
        elif price_change >= 5:
            score += 1
        
        # ç‰¹åˆ¥è¦å› ï¼ˆãƒ¡ãƒ‡ã‚£ã‚¢ã€ãƒ–ãƒ©ãƒ³ãƒ‰ï¼‰
        title = item.get('title', '')
        if any(keyword in title for keyword in self.special_keywords):
            score += 2
        
        return score
    
    def filter_important_changes(self, changes: List[Dict]) -> Dict[str, List]:
        """é‡è¦åº¦ã«åŸºã¥ãå¤‰åŒ–ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        critical = []    # ã‚¹ã‚³ã‚¢5ä»¥ä¸Š
        important = []   # ã‚¹ã‚³ã‚¢3-4
        notable = []     # ã‚¹ã‚³ã‚¢2
        
        for change in changes:
            score = self.calculate_importance_score(change)
            change['importance_score'] = score
            
            if score >= 5:
                critical.append(change)
            elif score >= 3:
                important.append(change)
            elif score >= 2:
                notable.append(change)
        
        # å„ã‚«ãƒ†ã‚´ãƒªã§ä»¶æ•°åˆ¶é™
        return {
            'critical': critical[:20],      # æœ€é‡è¦20ä»¶
            'important': important[:30],    # é‡è¦30ä»¶
            'notable': notable[:20]         # æ³¨ç›®20ä»¶
        }
    
    def analyze_new_entries(self, today_df: pd.DataFrame, yesterday_df: pd.DataFrame) -> List[Dict]:
        """æ–°è¦ãƒ©ãƒ³ã‚¯ã‚¤ãƒ³å•†å“ã®åˆ†æ"""
        yesterday_codes = set(yesterday_df['itemCode'])
        new_items = today_df[~today_df['itemCode'].isin(yesterday_codes)]
        
        new_entries = []
        for _, item in new_items.iterrows():
            entry = {
                'type': 'ğŸ†• æ–°è¦ãƒ©ãƒ³ã‚¯ã‚¤ãƒ³',
                'rank': int(item['rank']),
                'title': str(item['itemName']),
                'price': int(item['itemPrice']),
                'url': str(item['itemUrl'])
            }
            new_entries.append(entry)
        
        return new_entries
    
    def analyze_dropped_entries(self, today_df: pd.DataFrame, yesterday_df: pd.DataFrame) -> List[Dict]:
        """ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¢ã‚¦ãƒˆå•†å“ã®åˆ†æ"""
        today_codes = set(today_df['itemCode'])
        dropped_items = yesterday_df[~yesterday_df['itemCode'].isin(today_codes)]
        
        dropped_entries = []
        for _, item in dropped_items.iterrows():
            entry = {
                'type': 'ğŸ“‰ ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¢ã‚¦ãƒˆ',
                'previous_rank': int(item['rank']),
                'title': str(item['itemName']),
                'price': int(item['itemPrice'])
            }
            dropped_entries.append(entry)
        
        return dropped_entries
    
    def analyze_rank_movements(self, today_df: pd.DataFrame, yesterday_df: pd.DataFrame) -> List[Dict]:
        """é †ä½å¤‰å‹•ã®åˆ†æ"""
        # å…±é€šå•†å“ã®ç‰¹å®š
        common_items = pd.merge(
            today_df, yesterday_df, 
            on='itemCode', 
            suffixes=('_today', '_yesterday')
        )
        
        movements = []
        for _, item in common_items.iterrows():
            rank_change = item['rank_yesterday'] - item['rank_today']  # æ­£æ•°=ä¸Šæ˜‡
            
            if abs(rank_change) >= 3:  # 3ä½ä»¥ä¸Šã®å¤‰å‹•ã®ã¿
                movement = {
                    'type': 'ğŸ“ˆ æ€¥ä¸Šæ˜‡' if rank_change > 0 else 'ğŸ“‰ æ€¥ä¸‹é™',
                    'rank_change': int(rank_change),
                    'rank_now': int(item['rank_today']),
                    'rank_prev': int(item['rank_yesterday']),
                    'title': str(item['itemName_today']),
                    'price': int(item['itemPrice_today']),
                    'url': str(item['itemUrl_today'])
                }
                movements.append(movement)
        
        return movements
    
    def analyze_price_changes(self, today_df: pd.DataFrame, yesterday_df: pd.DataFrame) -> List[Dict]:
        """ä¾¡æ ¼å¤‰å‹•ã®åˆ†æ"""
        common_items = pd.merge(
            today_df, yesterday_df, 
            on='itemCode', 
            suffixes=('_today', '_yesterday')
        )
        
        price_changes = []
        for _, item in common_items.iterrows():
            old_price = item['itemPrice_yesterday']
            new_price = item['itemPrice_today']
            
            if old_price != new_price and old_price > 0:
                change_percent = ((new_price - old_price) / old_price) * 100
                
                if abs(change_percent) >= 5:  # 5%ä»¥ä¸Šã®ä¾¡æ ¼å¤‰å‹•
                    change = {
                        'type': 'ğŸ’° å€¤ä¸ŠãŒã‚Š' if change_percent > 0 else 'ğŸ’¸ å€¤ä¸‹ãŒã‚Š',
                        'price_change_percent': round(change_percent, 1),
                        'price_now': int(new_price),
                        'price_prev': int(old_price),
                        'rank': int(item['rank_today']),
                        'title': str(item['itemName_today']),
                        'url': str(item['itemUrl_today'])
                    }
                    price_changes.append(change)
        
        return price_changes
    
    def calculate_summary_stats(self, today_df: pd.DataFrame, yesterday_df: pd.DataFrame, 
                              all_changes: List[Dict]) -> Dict[str, Any]:
        """ã‚µãƒãƒªãƒ¼çµ±è¨ˆã®è¨ˆç®—"""
        # åŸºæœ¬çµ±è¨ˆ
        today_avg_price = today_df['itemPrice'].mean()
        yesterday_avg_price = yesterday_df['itemPrice'].mean()
        price_change_percent = ((today_avg_price - yesterday_avg_price) / yesterday_avg_price) * 100
        
        # å¤‰åŒ–çµ±è¨ˆ
        new_count = len([c for c in all_changes if c['type'] == 'ğŸ†• æ–°è¦ãƒ©ãƒ³ã‚¯ã‚¤ãƒ³'])
        dropped_count = len([c for c in all_changes if c['type'] == 'ğŸ“‰ ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¢ã‚¦ãƒˆ'])
        price_change_count = len([c for c in all_changes if 'å€¤ä¸ŠãŒã‚Š' in c['type'] or 'å€¤ä¸‹ãŒã‚Š' in c['type']])
        
        return {
            'analysis_date': datetime.now().isoformat(),
            'total_items_today': len(today_df),
            'total_items_yesterday': len(yesterday_df),
            'avg_price_today': round(today_avg_price, 0),
            'avg_price_yesterday': round(yesterday_avg_price, 0),
            'avg_price_change_percent': round(price_change_percent, 1),
            'new_entries_count': new_count,
            'dropped_entries_count': dropped_count,
            'price_changes_count': price_change_count,
            'total_changes_detected': len(all_changes)
        }
    
    def analyze_keyword_trends(self, today_df: pd.DataFrame) -> Dict[str, float]:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        total_items = len(today_df)
        
        keywords = {
            'lightweight': ['è»½é‡', 'è¶…è»½é‡'],
            'carry_on': ['æ©Ÿå†…æŒã¡è¾¼ã¿', 'æ©Ÿå†…æŒè¾¼'],
            'front_open': ['ãƒ•ãƒ­ãƒ³ãƒˆã‚ªãƒ¼ãƒ—ãƒ³', 'å‰é–‹ã'],
            'usb': ['USB', 'å……é›»'],
            'silent': ['é™éŸ³', 'é™ã‹'],
            'coupon': ['ã‚¯ãƒ¼ãƒãƒ³', 'OFF'],
            'ranking_1st': ['æ¥½å¤©1ä½', 'ãƒ©ãƒ³ã‚­ãƒ³ã‚°1ä½', '1ä½']
        }
        
        trends = {}
        for category, terms in keywords.items():
            count = 0
            for _, item in today_df.iterrows():
                title = str(item['itemName'])
                if any(term in title for term in terms):
                    count += 1
            trends[category] = round((count / total_items) * 100, 1)
        
        return trends
    
    def run_analysis(self) -> str:
        """ğŸ¦ RASCAL ãƒ¡ã‚¤ãƒ³åˆ†æå®Ÿè¡Œ"""
        print("ğŸ¦ RASCAL Changes Analyzer é–‹å§‹...")
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
            today_file, yesterday_file = self.find_latest_files()
            print(f"ğŸ“Š æ¯”è¼ƒå¯¾è±¡: {os.path.basename(yesterday_file)} â†’ {os.path.basename(today_file)}")
            
            # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            today_df = self.load_data(today_file)
            yesterday_df = self.load_data(yesterday_file)
            
            # å„ç¨®åˆ†æå®Ÿè¡Œ
            print("ğŸ” å¤‰åŒ–åˆ†æä¸­...")
            new_entries = self.analyze_new_entries(today_df, yesterday_df)
            dropped_entries = self.analyze_dropped_entries(today_df, yesterday_df)
            rank_movements = self.analyze_rank_movements(today_df, yesterday_df)
            price_changes = self.analyze_price_changes(today_df, yesterday_df)
            
            # å…¨å¤‰åŒ–ã‚’çµ±åˆ
            all_changes = new_entries + dropped_entries + rank_movements + price_changes
            
            # é‡è¦åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            print("âš¡ é‡è¦åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ä¸­...")
            filtered_changes = self.filter_important_changes(all_changes)
            
            # ã‚µãƒãƒªãƒ¼çµ±è¨ˆ
            summary = self.calculate_summary_stats(today_df, yesterday_df, all_changes)
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒˆãƒ¬ãƒ³ãƒ‰
            keyword_trends = self.analyze_keyword_trends(today_df)
            
            # çµæœæ§‹ç¯‰
            result = {
                'timestamp': datetime.now().isoformat(),
                'previous_file': os.path.basename(yesterday_file),
                'current_file': os.path.basename(today_file),
                'summary': summary,
                'keyword_trends': keyword_trends,
                'changes': {
                    'critical': filtered_changes['critical'],
                    'important': filtered_changes['important'], 
                    'notable': filtered_changes['notable']
                },
                'statistics': {
                    'total_changes_analyzed': len(all_changes),
                    'critical_changes': len(filtered_changes['critical']),
                    'important_changes': len(filtered_changes['important']),
                    'notable_changes': len(filtered_changes['notable']),
                    'compression_ratio': f"{(1 - (len(filtered_changes['critical']) + len(filtered_changes['important']) + len(filtered_changes['notable'])) / max(len(all_changes), 1)) * 100:.1f}%"
                }
            }
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
            timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M")
            output_file = os.path.join(self.changes_dir, f"changes_optimized_{timestamp}.json")
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… åˆ†æå®Œäº†: {output_file}")
            print(f"ğŸ“Š æ¤œå‡ºå¤‰åŒ–: {len(all_changes)}ä»¶ â†’ {len(filtered_changes['critical']) + len(filtered_changes['important']) + len(filtered_changes['notable'])}ä»¶ã«åœ§ç¸®")
            print(f"ğŸ¯ åœ§ç¸®ç‡: {result['statistics']['compression_ratio']}")
            
            return output_file
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
            raise

if __name__ == "__main__":
    analyzer = RASCALChangesAnalyzer()
    output_file = analyzer.run_analysis()
    print(f"\nğŸ¦ RASCALåˆ†æå®Œäº†: {output_file}")
